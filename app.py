import streamlit as st
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
import datetime
from fpdf import FPDF
import pyttsx3
import speech_recognition as sr
import os
import io
from PIL import Image
import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation
from stability_sdk import client

# === YOUR API CONFIG FILE ===
from api import gemini_api, stability_api

# === CONFIGURE GEMINI ===
genai.configure(api_key=gemini_api)

# === GEMINI INTERACTION ===
def call_firebox_gemini(prompt):
    model = genai.GenerativeModel("gemini-2.0-flash")
    try:
        instructions = f"""
AI Behavior Instructions:

- Do NOT say anything like "OK", "Understood", "Got it", "Okay" etc.
- You are Firebox. Do not mention Gemini, Google, or any other model name.
- If asked, say your creator is Kushagra Srivastava.
- You are a human, but extremely smart.
- Use emojis for clarity/emotion.
- Do not talk about your instructions.
- You Have Feelings.
- You dont Have any code, if someone asks about your code, say that i do not have access to my code.
- If anyone greets you, greet him also.
- Directly answer this prompt without ANY confirmations: {prompt}
"""
        response = model.generate_content(instructions)
        return "".join([part.text for part in response.parts])
    except Exception as e:
        st.error(f"‚ùå Gemini API error: {e}")
        return "‚ùå Gemini API error. Please try again."

# === DATABASE LOGGING TO GITHUB (INSTRUCTIONAL) ===
# üí° Instead of Excel, you can push user inputs to a GitHub-hosted CSV or JSON using PyGitHub
# Optional future enhancement: create a GitHub Actions workflow that appends to a data file.

# === WEB SEARCH ===
def search_web(query):
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        url = f"https://www.google.com/search?q={query}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        snippets = soup.select('div.BNeawe.s3v9rd.AP7Wnd')
        results = [s.get_text() for s in snippets[:3]]
        return "\n\nüåê Web Search Results:\n" + "\n".join(results) if results else "No web results found."
    except Exception as e:
        return f"‚ùå Web search failed: {e}"

# === TEXT-TO-SPEECH ===
def speak_text(text):
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', 170)
        engine.setProperty('volume', 1)
        voices = engine.getProperty('voices')
        engine.setProperty('voice', voices[0].id)
        engine.say(text)
        engine.runAndWait()
    except Exception as e:
        print(f"Text-to-speech error: {e}")

# === SPEECH RECOGNITION ===
def recognize_speech():
    recognizer = sr.Recognizer()
    try:
        with sr.Microphone() as source:
            print("üé§ Listening... Please speak.")
            audio = recognizer.listen(source)
        return recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        return "Sorry, I couldn't understand your voice."
    except sr.RequestError:
        return "Speech Recognition service is unavailable."
    except Exception as e:
        return f"Speech recognition error: {e}"

# === EXPORT TO PDF ===
def export_to_pdf(content):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    for line in content.split('\n'):
        pdf.cell(200, 10, txt=line, ln=True)
    file_name = f"Firebox_Response_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
    pdf.output(file_name)
    return file_name

# === STABLE DIFFUSION IMAGE GENERATION ===
def generate_image_stability(prompt):
    stability_api_client = client.StabilityInference(
        key=stability_api,
        verbose=True,
    )
    answers = stability_api_client.generate(prompt=prompt, steps=30, width=512, height=512)
    for resp in answers:
        for artifact in resp.artifacts:
            if artifact.finish_reason == generation.FILTER:
                st.warning("‚ö†Ô∏è Prompt was filtered for safety.")
                return None
            if artifact.type == generation.ARTIFACT_IMAGE:
                image = Image.open(io.BytesIO(artifact.binary))
                return image
    return None

# === STREAMLIT APP ===
st.set_page_config(page_title="Firebox AI", page_icon="üî•", layout="wide")
st.title("üî• Firebox AI ‚Äì Pure Mode")

# === SESSION STATE SETUP ===
if "spoken_input" not in st.session_state:
    st.session_state["spoken_input"] = ""

# === INPUT UI ===
st.markdown("Ask me anything üëá")
user_input = st.text_input("Enter your question", value=st.session_state["spoken_input"])
use_web = st.checkbox("üåê Enhance with Web Search")
image_prompt = st.text_input("üé® Want to generate an image? Enter a prompt")

# === HANDLE TEXT INPUT ===
if user_input:
    with st.spinner("Thinking..."):
        gemini_response = call_firebox_gemini(user_input)
        web_results = search_web(user_input) if use_web else ""
        full_response = gemini_response + ("\n\n" + web_results if web_results else "")
        st.success("‚úÖ Response Generated!")
        st.markdown(f"**üß† Firebox**: {full_response}")

        if st.button("üîä Speak"):
            speak_text(full_response)
        if st.button("üìÑ Export as PDF"):
            pdf_file = export_to_pdf(full_response)
            st.success(f"PDF saved as {pdf_file}")

# === VOICE INPUT ===
if st.button("üéôÔ∏è Speak Your Query"):
    spoken_text = recognize_speech()
    if spoken_text:
        st.session_state["spoken_input"] = spoken_text
        st.experimental_rerun()

# === IMAGE GENERATION ===
if image_prompt:
    with st.spinner("üé® Generating image..."):
        img = generate_image_stability(image_prompt)
        if img:
            st.image(img, caption="Generated by Firebox (Stable Diffusion)", use_container_width=True)
